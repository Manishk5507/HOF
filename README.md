
# Title

#### Gesture Harmony

# Description

In today's world where the cost of living has skyrocketed and majority of the crowd has little to no funds to spend on their interests and hobbies, we introduce a groundbreaking and innovative idea that will change the instrument learning experience forever. With the help of AI and computer vision technology, our solution brings an affordable option to the table which can help you learn any instrument of your choice without any physical necessities. It replicates the instrument of your choice via a virtual interface, this helps aspiring musicians learn and explore without lavishing on new instruments and academies for exampale we can learn Drum , Xylophone , Piano , etc... from this website.

## Dataset

- Download the dataset for custom training from the Github Link
- [Dataset_Github_Link](https://github.com/Manishk5507/HOF/tree/main/Python_Files/Sound%26Images)

## Download Gesture Harmony Model
- Download the Gesture Harmony Model manually: (file name) from the following Github link
- [Github link ](https://github.com/Manishk5507/HOF/tree/main/Python_Files)
## API Reference

#### Get all items

- The API's that we have used are given below.
- [Google Fonts](https://fonts.googleapis.com/css?family=Poppins:500,600,700,900&display=swap)
- [Fonts Awesome](https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css)
- [ Tweenmax GSAP ](https://cdnjs.cloudflare.com/ajax/libs/gsap/2.1.2/TweenMax.min.js)

## Demo

Gesture Harmony website hosted link.
- [ website ](https://harmonic-gesture.vercel.app/)



## Tech Stack Used
- opencv-python
- numpy
- time
- pygame
- pickle
- streamlit
- cvzone
- html (Hyper Text Markup Language)
- css (Cascading Style Sheet )
- JavaScript
- GSAP
- Node.js
- Express.js
- MongoDb
- jsonwebtoken (JWT)
- bcryptjs
- cors



## Deployment

To deploy this project run

```bash
copy the .py files and run in any code editor with requirements pre-installed

run the command below to run the code in local host

$ streamlit run <pythonfile_name.py>

```


# Contributors

- Apoorv Mittal (created the main ML model of Xylophone by using opencv , also deployed the ML model and helped in linking the ML model with the front end part , also have contributed in other ML models)
-->[Linkedin]()
- Ujjwal Goyal (created the ML models of Drum and piano by using opencv also have given the idea of playing the instruments with the help of motion detection , also contributed in creating the pitch-deck)
 -->[Linkedin]()
- Manish Kumar  (Handled all the back-end related code and functionalities ,also have contributed in the front-end part of creating the main home page and other pages also. And have integrated the ML model with the front-end part and deployed and hosted the website )

-->[Linkedin](https://www.linkedin.com/in/manish-kumar-257580291?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app)
- Ashwin Gajbhiye   (Handled the front-end part like creating different web-pages and also contributed in the back-end part . And have created the pitch-deck , also helped in some of the Deployment and hosting part of the website)

-->[Linkedin](https://www.linkedin.com/in/ashwin-gajbhiye-902b07291)